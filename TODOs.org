#+TITLE: TODOs
#+OPTIONS: tex:t
#+OPTIONS: toc:nil

* General
** TODO complete documentation in README.md s.t. all scripts are mentioned
* Dataset recording
** DONE to synchronize all sensors and to furthermore be able to simulate at any wanted framerates guide the implementation according to 'examples/synchronous_mode.py'
  CLOSED: [2019-08-16 Fri 09:08]
** TODO sensors_at_vehicle_sync.py does not run when client and server are invoked on different machines
*** TODO try: move code for spawning actors into 'CarlaSyncMode' context, i.e. after lines 'with CarlaSyncMode(...'
**** maybe the asynchronizity is comming from the fact that the sensors are spawned not within synchronous mode and therefore start capturing at different times
*** TODO try: test old implementation of 'synchronous_mode.py' (version 0.9.5)
**** if it will run remotely aswell as locally than try upwards through git commits till the version that does not run anymore and figure out the buggy line
**** if it will not run remotely then the problem maybe relates closer to the subsystem and should no longer be investigated -> maybe then ask in forum ?
** DONE add stereo camera support, i.e. add additional camera sensor right of current one
  CLOSED: [2019-08-16 Fri 09:08]
** DONE add depth camera support placed at same position as left RGB camera
  CLOSED: [2019-07-29 Mon 11:49]
** DONE add semantic segmantation camera support placed at same position as left RGB camera
  CLOSED: [2019-07-29 Mon 11:49]
** DONE add command line argument parser to support for command line arguments 
  CLOSED: [2019-08-01 Thu 16:25]
** DONE save sensor measurements to disk 
  CLOSED: [2019-07-30 Tue 21:35]
*** use same data structure as KITTI
** DONE transform poses s.t. they start in origin
  CLOSED: [2019-08-16 Fri 09:11]
** DONE rename intrinsics.txt to config.txt and store several relevant informations about the simulation like:
  CLOSED: [2019-08-16 Fri 09:11]
** DONE save GT poses to disk
  CLOSED: [2019-08-16 Fri 09:11]
** DONE shift timestamps s.t. they start at 0.0 seconds
  CLOSED: [2019-08-16 Fri 09:11]
** DONE save camera intrinsics to disk
  CLOSED: [2019-08-16 Fri 09:11]
** DONE write sensor measurements to buffer first and save to disk in simultanous thread (else runtime of simulation will be heavily affected)
  CLOSED: [2019-08-16 Fri 09:11]
** DONE visualize the GT poses with evo-kitti tool to check if the representation is sufficient
  CLOSED: [2019-08-16 Fri 09:11]
** DONE validate rotation matrix computed from yaw, pitch, roll
  CLOSED: [2019-08-16 Fri 09:11]
** DONE save frame-to-frame relative poses to disk
  CLOSED: [2019-08-16 Fri 09:11]
** DONE validate relative poses by concatenating them to back to absolute trajectory
  CLOSED: [2019-08-16 Fri 09:11]
** DONE validate GT rotations with extra tool that visualizes the pose orientations
  CLOSED: [2019-08-16 Fri 09:11]
** DONE transform GT poses from CARLA coordinate system to right handed one
  CLOSED: [2019-08-16 Fri 09:11]
** DONE validate if x (roll) rotation is correctly transformed too
  CLOSED: [2019-08-16 Fri 09:11]
** DONE reconstruct and validate carla world coordinate system
  CLOSED: [2019-08-16 Fri 09:11]
** DONE record test sequences and test on ORB-SLAM2 (additionally on libVISO2 or my own implementation)
  CLOSED: [2019-08-16 Fri 09:11]
** DONE write roslaunch script to easily visualize trajectory with rviz
  CLOSED: [2019-08-16 Fri 09:11]
** DONE write roslaunch script to easily convert GT poses to bagfile
  CLOSED: [2019-08-16 Fri 09:11]
** DONE save another poses file named 'poses_nulled_6.txt' that keeps the poses in the form: [tx, ty, tz, roll, pitch, yaw]
  CLOSED: [2019-10-14 Mon 14:09]
*** Low Priority
**** TODO make display_sensors function more generic, s.t. arbitrary sensors (or selections from them) will be visualized
**** TODO add random weather selection at start
**** TODO add command line argument for weather presets
**** TODO add support for dynamic scenes by adding vehicles and pedestrians to the world
**** TODO add command line argument for static/dynamic world
**** TODO add command line argument that allows for setting arbitrary sensor constellations using .JSON file

* Dataset Analysis
** TODO add script that iterates over a set of labeled sequences and filters them in order to get rid of concentraitons in the labels
*** e.g. cluster the 6 dof poses into classes, add each images-label pair to a class and make a histogram. Watch that each histogram bin will finally be of the same size.
*** additionally one could consider the variance of the input images of each poses class. Therefore depht images should additionally be recorded. The variance can then be computed over the depth images.
**** depth images are better suited for the variance computation than RGB images since RGB images have lots of additional variance due to differences in lighting, exposure and other imaging artifacts.
**** NOTE computing the variance over depth images comes with the downside that the variance in the image texture is not considered, but we usually also want to increase the variance within that quantity.
