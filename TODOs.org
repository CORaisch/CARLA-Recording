#+TITLE: TODOs
#+OPTIONS: tex:t
#+OPTIONS: toc:nil

* Dataset Generation from CARLA
** High Priority
*** DONE to synchronize all sensors and to furthermore be able to simulate at any wanted framerates guide the implementation according to 'examples/synchronous_mode.py'
    CLOSED: [2019-08-16 Fri 09:08]
*** TODO sensors_at_vehicle_sync.py does not run when client and server are invoked on different machines
**** TODO try: move code for spawning actors into 'CarlaSyncMode' context, i.e. after lines 'with CarlaSyncMode(...'
***** maybe the asynchronizity is comming from the fact that the sensors are spawned not within synchronous mode and therefore start capturing at different times
**** TODO try: test old implementation of 'synchronous_mode.py' (version 0.9.5)
***** if it will run remotely aswell as locally than try upwards through git commits till the version that does not run anymore and figure out the buggy line
***** if it will not run remotely then the problem maybe relates closer to the subsystem and should no longer be investigated -> maybe then ask in forum ?
*** DONE add stereo camera support, i.e. add additional camera sensor right of current one
    CLOSED: [2019-08-16 Fri 09:08]
*** DONE add depth camera support placed at same position as left RGB camera
    CLOSED: [2019-07-29 Mon 11:49]
*** DONE add semantic segmantation camera support placed at same position as left RGB camera
    CLOSED: [2019-07-29 Mon 11:49]
*** DONE add command line argument parser to support for command line arguments 
    CLOSED: [2019-08-01 Thu 16:25]
*** DONE save sensor measurements to disk 
    CLOSED: [2019-07-30 Tue 21:35]
**** use same data structure as KITTI
*** DONE transform poses s.t. they start in origin
    CLOSED: [2019-08-16 Fri 09:11]
*** DONE rename intrinsics.txt to config.txt and store several relevant informations about the simulation like:
    CLOSED: [2019-08-16 Fri 09:11]
*** DONE save GT poses to disk
    CLOSED: [2019-08-16 Fri 09:11]
*** DONE shift timestamps s.t. they start at 0.0 seconds
    CLOSED: [2019-08-16 Fri 09:11]
*** DONE save camera intrinsics to disk
    CLOSED: [2019-08-16 Fri 09:11]
*** DONE write sensor measurements to buffer first and save to disk in simultanous thread (else runtime of simulation will be heavily affected)
    CLOSED: [2019-08-16 Fri 09:11]
*** DONE visualize the GT poses with evo-kitti tool to check if the representation is sufficient
    CLOSED: [2019-08-16 Fri 09:11]
*** DONE validate rotation matrix computed from yaw, pitch, roll
    CLOSED: [2019-08-16 Fri 09:11]
*** DONE save frame-to-frame relative poses to disk
    CLOSED: [2019-08-16 Fri 09:11]
*** DONE validate relative poses by concatenating them to back to absolute trajectory
    CLOSED: [2019-08-16 Fri 09:11]
*** DONE validate GT rotations with extra tool that visualizes the pose orientations
    CLOSED: [2019-08-16 Fri 09:11]
*** DONE transform GT poses from CARLA coordinate system to right handed one
    CLOSED: [2019-08-16 Fri 09:11]
*** DONE validate if x (roll) rotation is correctly transformed too
    CLOSED: [2019-08-16 Fri 09:11]
*** DONE reconstruct and validate carla world coordinate system
    CLOSED: [2019-08-16 Fri 09:11]
*** DONE record test sequences and test on ORB-SLAM2 (additionally on libVISO2 or my own implementation)
    CLOSED: [2019-08-16 Fri 09:11]
*** DONE write roslaunch script to easily visualize trajectory with rviz
    CLOSED: [2019-08-16 Fri 09:11]
*** DONE write roslaunch script to easily convert GT poses to bagfile
    CLOSED: [2019-08-16 Fri 09:11]
** Low Priority
*** TODO make display_sensors function more generic, s.t. arbitrary sensors (or selections from them) will be visualized
*** TODO add random weather selection at start
*** TODO add command line argument for weather presets
*** TODO add support for dynamic scenes by adding vehicles and pedestrians to the world
*** TODO add command line argument for static/dynamic world
*** TODO add command line argument that allows for setting arbitrary sensor constellations using .JSON file
* Dataset Preparation
** parameters config-file should support
*** DONE RGB/Grayscale
    CLOSED: [2019-08-16 Fri 17:37]
*** DONE size of input images
    CLOSED: [2019-08-16 Fri 17:37]
*** DONE sequence length
    CLOSED: [2019-08-16 Fri 17:37]
**** how many consecutive frames in time should be used per training data (e.g. use frames at t1, t2 and t3)
*** DONE sequence width
    CLOSED: [2019-08-16 Fri 17:37]
**** how many frames should be used per time (e.g. monocular, stereo, etc.)
*** DONE label selection
    CLOSED: [2019-08-16 Fri 17:37]
****  if sequence width is greater than 2 the user needs to select between which frames the relative motion should be trained
*** DONE preprocessing of input images
    CLOSED: [2019-08-16 Fri 17:37]
**** offer presets of common filtering operations
**** reflect ways on how to offer callback for more flexible usage
*** DONE training location
    CLOSED: [2019-08-16 Fri 17:37]
**** train on local CPU, local GPU or on cluster 
*** DONE training mode
    CLOSED: [2019-08-16 Fri 17:37]
**** online or offline training
** DONE implement config file parser
   CLOSED: [2019-08-16 Fri 17:35]
** DONE at the start of the script it should be checked if all relevant tags are defined in config file
   CLOSED: [2019-08-16 Fri 17:36]
*** relevant tags: input [images [format, width, height], length, frame [width], label [start, end]], training [path, location, mode]
**** at least one frame must be specified
** TODO make config overview looking nicer
** TODO reflect in which format the configuration should be supported
*** XML comes with great parser support
*** but in order to support for flexible preprocessing via callback we need to come up with alternative config specification
* CNN Implementation
** use Tensorflow 1, Tensorflow 2 or PyTorch ?
* Dataset Analysis
* KITTI Training for Reference
* Unsupervised Model Support
