#+TITLE: TODOs
#+OPTIONS: tex:t
#+OPTIONS: toc:nil
* High Priority
** DONE to synchronize all sensors and to furthermore be able to simulate at any wanted framerates guide the implementation according to 'examples/synchronous_mode.py'
   CLOSED: [2019-07-29 Mon 13:16]
** TODO sensors_at_vehicle_sync.py does not run when client and server are invoked on different machines
*** TODO try: move code for spawning actors into 'CarlaSyncMode' context, i.e. after lines 'with CarlaSyncMode(...'
**** maybe the asynchronizity is comming from the fact that the sensors are spawned not within synchronous mode and therefore start capturing at different times
*** TODO try: test old implementation of 'synchronous_mode.py' (version 0.9.5)
**** if it will run remotely aswell as locally than try upwards through git commits till the version that does not run anymore and figure out the buggy line
**** if it will not run remotely then the problem maybe relates closer to the subsystem and should no longer be investigated -> maybe then ask in forum ?
** DONE add stereo camera support, i.e. add additional camera sensor right of current one
   CLOSED: [2019-07-29 Mon 11:49]
** DONE add depth camera support placed at same position as left RGB camera
   CLOSED: [2019-07-29 Mon 11:49]
** DONE add semantic segmantation camera support placed at same position as left RGB camera
   CLOSED: [2019-07-29 Mon 11:49]
** DONE add command line argument parser to support for command line arguments 
   CLOSED: [2019-08-01 Thu 16:25]
** DONE save sensor measurements to disk 
   CLOSED: [2019-07-30 Tue 21:35]
*** use same data structure as KITTI
** DONE transform poses s.t. they start in origin
   CLOSED: [2019-08-02 Fri 14:23]
*** apply inverste transform of very firsts pose to all poses
** TODO make display_sensors function more generic, s.t. arbitrary sensors (or selections from them) will be visualized
** DONE save GT poses to disk
   CLOSED: [2019-07-31 Wed 16:09]
*** maybe transform GT coord system to KITTI as well ?
** DONE save camera intrinsics to disk
   CLOSED: [2019-08-01 Thu 18:35]
** DONE write sensor measurements to buffer first and save to disk in simultanous thread (else runtime of simulation will be heavily affected)
   CLOSED: [2019-08-01 Thu 00:25]
** DONE visualize the GT poses with evo-kitti tool to check if the representation is sufficient
   CLOSED: [2019-07-31 Wed 16:09]
** DONE validate rotation matrix computed from yaw, pitch, roll
   CLOSED: [2019-08-02 Fri 13:39]
*** rotate test-vectors with rotation matrix and with carla.Transform.transform(...) function and compare results
** TODO save frame-to-frame relative poses to disk
** DONE validate GT rotations with extra tool that visualizes the pose orientations
   CLOSED: [2019-08-03 Sat 22:46]
*** write simple py-ros tool that reads in the trajectories from simultor and outputs geometry_msgs/Pose on a topic -> record rosbag from topic -> visualize with rviz
** TODO provide transform between CARLA coordinate system and the one from OpenCV
** DONE reconstruct and validate carla world coordinate system
   CLOSED: [2019-08-02 Fri 10:32]
*** spawn object at origin and other object at {x,y,z} = +1
** TODO record test sequences and test on ORB-SLAM2 (additionally on libVISO2 or my own implementation)
*** write config file for ORB-SLAM2

* Low Priority
** TODO add random weather selection at start
** TODO add command line argument for weather presets
** TODO add support for dynamic scenes by adding vehicles and pedestrians to the world
** TODO add command line argument for static/dynamic world
** TODO add command line argument that allows for setting arbitrary sensor constellations using .JSON file
